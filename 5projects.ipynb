{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a36eac8-15ed-4685-b037-b78415cab84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training accuracy: 1.0\n",
      "Epoch 1: Validation accuracy: 1.0\n",
      "Epoch 2: Training accuracy: 1.0\n",
      "Epoch 2: Validation accuracy: 1.0\n",
      "Epoch 3: Training accuracy: 1.0\n",
      "Epoch 3: Validation accuracy: 1.0\n",
      "Epoch 4: Training accuracy: 1.0\n",
      "Epoch 4: Validation accuracy: 1.0\n",
      "Epoch 5: Training accuracy: 1.0\n",
      "Epoch 5: Validation accuracy: 1.0\n",
      "Epoch 6: Training accuracy: 1.0\n",
      "Epoch 6: Validation accuracy: 1.0\n",
      "Epoch 7: Training accuracy: 1.0\n",
      "Epoch 7: Validation accuracy: 1.0\n",
      "Epoch 8: Training accuracy: 1.0\n",
      "Epoch 8: Validation accuracy: 1.0\n",
      "Epoch 9: Training accuracy: 1.0\n",
      "Epoch 9: Validation accuracy: 1.0\n",
      "Epoch 10: Training accuracy: 1.0\n",
      "Epoch 10: Validation accuracy: 1.0\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Define paths to image folders\n",
    "train_folder = '/home/asreen-mohammad/Desktop/project/train'\n",
    "validation_folder = '/home/asreen-mohammad/Desktop/project/validation'\n",
    "test_folder = '/home/asreen-mohammad/Desktop/project/test'\n",
    "\n",
    "# Function to load images from a folder\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        if os.path.isfile(img_path):\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (28, 28))  # Resize image to 28x28 (adjust as needed)\n",
    "                images.append(img.flatten())  # Flatten the image and add to list\n",
    "    return images\n",
    "\n",
    "# Load training images and labels\n",
    "train_images = load_images_from_folder(train_folder)\n",
    "train_outputs = np.zeros(len(train_images))  # Assuming binary classification (0 or 1)\n",
    "\n",
    "# Load validation images and labels\n",
    "validation_images = load_images_from_folder(validation_folder)\n",
    "validation_outputs = np.zeros(len(validation_images))  # Assuming binary classification (0 or 1)\n",
    "\n",
    "# Load test images and labels\n",
    "test_images = load_images_from_folder(test_folder)\n",
    "test_outputs = np.zeros(len(test_images))  # Assuming binary classification (0 or 1)\n",
    "\n",
    "# Initialize weights (+1 for bias)\n",
    "weights = np.zeros(train_images[0].shape[0] + 1)\n",
    "\n",
    "# Training the perceptron\n",
    "learning_rate = 0.1\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    train_results = []\n",
    "    for inputs, output in zip(train_images, train_outputs):\n",
    "        inputs_with_bias = np.insert(inputs, 0, 1)  # Add bias term\n",
    "        prediction = np.dot(inputs_with_bias, weights)\n",
    "        prediction = 1 if prediction > 0 else 0\n",
    "        weights += learning_rate * (output - prediction) * inputs_with_bias\n",
    "        train_results.append(prediction == output)\n",
    "    print(f\"Epoch {epoch + 1}: Training accuracy:\", np.mean(train_results) if train_results else 0)\n",
    "\n",
    "    # Validation\n",
    "    validation_results = []\n",
    "    for inputs, output in zip(validation_images, validation_outputs):\n",
    "        inputs_with_bias = np.insert(inputs, 0, 1)  # Add bias term\n",
    "        prediction = np.dot(inputs_with_bias, weights)\n",
    "        prediction = 1 if prediction > 0 else 0\n",
    "        validation_results.append(prediction == output)\n",
    "    print(f\"Epoch {epoch + 1}: Validation accuracy:\", np.mean(validation_results) if validation_results else 0)\n",
    "\n",
    "# Testing\n",
    "test_results = []\n",
    "for inputs, output in zip(test_images, test_outputs):\n",
    "    inputs_with_bias = np.insert(inputs, 0, 1)  # Add bias term\n",
    "    prediction = np.dot(inputs_with_bias, weights)\n",
    "    prediction = 1 if prediction > 0 else 0\n",
    "    test_results.append(prediction == output)\n",
    "print(\"Test accuracy:\", np.mean(test_results) if test_results else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99bb69d6-eae7-44a6-8396-9d53725a9c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/asreen-mohammad/Desktop/project/train/saprate.py: cannot identify image file '/home/asreen-mohammad/Desktop/project/train/saprate.py'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/train/MNIST/raw/t10k-images-idx3-ubyte: cannot identify image file '/home/asreen-mohammad/Desktop/project/train/MNIST/raw/t10k-images-idx3-ubyte'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/train/MNIST/raw/t10k-images-idx3-ubyte.gz: cannot identify image file '/home/asreen-mohammad/Desktop/project/train/MNIST/raw/t10k-images-idx3-ubyte.gz'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/train/MNIST/raw/t10k-labels-idx1-ubyte: cannot identify image file '/home/asreen-mohammad/Desktop/project/train/MNIST/raw/t10k-labels-idx1-ubyte'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/train/MNIST/raw/t10k-labels-idx1-ubyte.gz: cannot identify image file '/home/asreen-mohammad/Desktop/project/train/MNIST/raw/t10k-labels-idx1-ubyte.gz'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/train/MNIST/raw/train-images-idx3-ubyte: cannot identify image file '/home/asreen-mohammad/Desktop/project/train/MNIST/raw/train-images-idx3-ubyte'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/train/MNIST/raw/train-images-idx3-ubyte.gz: cannot identify image file '/home/asreen-mohammad/Desktop/project/train/MNIST/raw/train-images-idx3-ubyte.gz'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/train/MNIST/raw/train-labels-idx1-ubyte: cannot identify image file '/home/asreen-mohammad/Desktop/project/train/MNIST/raw/train-labels-idx1-ubyte'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/train/MNIST/raw/train-labels-idx1-ubyte.gz: cannot identify image file '/home/asreen-mohammad/Desktop/project/train/MNIST/raw/train-labels-idx1-ubyte.gz'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/validation/MNIST/raw/t10k-images-idx3-ubyte: cannot identify image file '/home/asreen-mohammad/Desktop/project/validation/MNIST/raw/t10k-images-idx3-ubyte'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/validation/MNIST/raw/t10k-images-idx3-ubyte.gz: cannot identify image file '/home/asreen-mohammad/Desktop/project/validation/MNIST/raw/t10k-images-idx3-ubyte.gz'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/validation/MNIST/raw/t10k-labels-idx1-ubyte: cannot identify image file '/home/asreen-mohammad/Desktop/project/validation/MNIST/raw/t10k-labels-idx1-ubyte'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/validation/MNIST/raw/t10k-labels-idx1-ubyte.gz: cannot identify image file '/home/asreen-mohammad/Desktop/project/validation/MNIST/raw/t10k-labels-idx1-ubyte.gz'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/validation/MNIST/raw/train-images-idx3-ubyte: cannot identify image file '/home/asreen-mohammad/Desktop/project/validation/MNIST/raw/train-images-idx3-ubyte'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/validation/MNIST/raw/train-images-idx3-ubyte.gz: cannot identify image file '/home/asreen-mohammad/Desktop/project/validation/MNIST/raw/train-images-idx3-ubyte.gz'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/validation/MNIST/raw/train-labels-idx1-ubyte: cannot identify image file '/home/asreen-mohammad/Desktop/project/validation/MNIST/raw/train-labels-idx1-ubyte'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/validation/MNIST/raw/train-labels-idx1-ubyte.gz: cannot identify image file '/home/asreen-mohammad/Desktop/project/validation/MNIST/raw/train-labels-idx1-ubyte.gz'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/test/MNIST/raw/t10k-images-idx3-ubyte: cannot identify image file '/home/asreen-mohammad/Desktop/project/test/MNIST/raw/t10k-images-idx3-ubyte'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/test/MNIST/raw/t10k-images-idx3-ubyte.gz: cannot identify image file '/home/asreen-mohammad/Desktop/project/test/MNIST/raw/t10k-images-idx3-ubyte.gz'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/test/MNIST/raw/t10k-labels-idx1-ubyte: cannot identify image file '/home/asreen-mohammad/Desktop/project/test/MNIST/raw/t10k-labels-idx1-ubyte'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/test/MNIST/raw/t10k-labels-idx1-ubyte.gz: cannot identify image file '/home/asreen-mohammad/Desktop/project/test/MNIST/raw/t10k-labels-idx1-ubyte.gz'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/test/MNIST/raw/train-images-idx3-ubyte: cannot identify image file '/home/asreen-mohammad/Desktop/project/test/MNIST/raw/train-images-idx3-ubyte'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/test/MNIST/raw/train-images-idx3-ubyte.gz: cannot identify image file '/home/asreen-mohammad/Desktop/project/test/MNIST/raw/train-images-idx3-ubyte.gz'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/test/MNIST/raw/train-labels-idx1-ubyte: cannot identify image file '/home/asreen-mohammad/Desktop/project/test/MNIST/raw/train-labels-idx1-ubyte'\n",
      "Skipping /home/asreen-mohammad/Desktop/project/test/MNIST/raw/train-labels-idx1-ubyte.gz: cannot identify image file '/home/asreen-mohammad/Desktop/project/test/MNIST/raw/train-labels-idx1-ubyte.gz'\n",
      "Epoch [1/10], Loss: 0.2531, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Epoch [2/10], Loss: 0.0005, Train Acc: 1.0000, Val Acc: 1.0000\n",
      "Testing Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "training_path = \"/home/asreen-mohammad/Desktop/project/train\"\n",
    "validation_path = \"/home/asreen-mohammad/Desktop/project/validation\"\n",
    "testing_path = \"/home/asreen-mohammad/Desktop/project/test\"\n",
    "\n",
    "root = training_path\n",
    "transform = transform\n",
    "samples = []\n",
    "for root, _, fnames in sorted(os.walk(root)):\n",
    "    for fname in sorted(fnames):\n",
    "        path = os.path.join(root, fname)\n",
    "        try:\n",
    "            img = Image.open(path).convert('L')\n",
    "            samples.append((path, img))\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {path}: {str(e)}\")\n",
    "\n",
    "train_loader = DataLoader([(transform(sample[1]), 0) for sample in samples], batch_size=32, shuffle=True)\n",
    "\n",
    "root = validation_path\n",
    "transform = transform\n",
    "samples = []\n",
    "for root, _, fnames in sorted(os.walk(root)):\n",
    "    for fname in sorted(fnames):\n",
    "        path = os.path.join(root, fname)\n",
    "        try:\n",
    "            img = Image.open(path).convert('L')\n",
    "            samples.append((path, img))\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {path}: {str(e)}\")\n",
    "\n",
    "val_loader = DataLoader([(transform(sample[1]), 0) for sample in samples], batch_size=32, shuffle=False)\n",
    "\n",
    "root = testing_path\n",
    "transform = transform\n",
    "samples = []\n",
    "for root, _, fnames in sorted(os.walk(root)):\n",
    "    for fname in sorted(fnames):\n",
    "        path = os.path.join(root, fname)\n",
    "        try:\n",
    "            img = Image.open(path).convert('L')\n",
    "            samples.append((path, img))\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {path}: {str(e)}\")\n",
    "\n",
    "test_loader = DataLoader([(transform(sample[1]), 0) for sample in samples], batch_size=32, shuffle=False)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28 * 28, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(2):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    # Calculate training accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in train_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # Calculate validation accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    val_acc = correct / total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/10], Loss: {epoch_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "test_acc = correct / total\n",
    "print(f\"Testing Accuracy: {test_acc:.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e381b31-9016-49b6-8964-65946e31b7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.4334286018418846\n",
      "Epoch 2, Loss: 0.18082173574385865\n",
      "Epoch 3, Loss: 0.13175720704288055\n",
      "Epoch 4, Loss: 0.10466192980379407\n",
      "Epoch 5, Loss: 0.08882242955790243\n",
      "Epoch 6, Loss: 0.0778050919236335\n",
      "Epoch 7, Loss: 0.06961221717871535\n",
      "Epoch 8, Loss: 0.06115008197516589\n",
      "Epoch 9, Loss: 0.053315855079507424\n",
      "Epoch 10, Loss: 0.04903542823637781\n",
      "Training Accuracy: 98.56333333333333 %\n",
      "Test Accuracy: 97.56 %\n",
      "Validation Accuracy: 97.56 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define transforms for preprocessing\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Load data from folders\n",
    "train_data = datasets.MNIST('/home/asreen-mohammad/Desktop/project/train', download=True, train=True, transform=transform)\n",
    "validation_data = datasets.MNIST('/home/asreen-mohammad/Desktop/project/validation', download=True, train=False, transform=transform)\n",
    "test_data = datasets.MNIST('/home/asreen-mohammad/Desktop/project/test', download=True, train=False, transform=transform)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# Multi-layer perceptron (MLP) model\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(784, 128),  # input layer (28x28) -> hidden layer (128)\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),  # hidden layer (128) -> hidden layer (64)\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10)  # hidden layer (64) -> output layer (10)\n",
    ")\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(mlp.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Train the network\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.view(-1, 784)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = mlp(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/i}')\n",
    "\n",
    "# Evaluate on training set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.view(-1, 784)\n",
    "        outputs = mlp(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f'Training Accuracy: {100 * correct / total} %')\n",
    "\n",
    "# Evaluate on test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.view(-1, 784)\n",
    "        outputs = mlp(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f'Test Accuracy: {100 * correct / total} %')\n",
    "\n",
    "# Evaluate on validation set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in validation_loader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.view(-1, 784)\n",
    "        outputs = mlp(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f'Validation Accuracy: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73210b16-5c9d-447d-a5cf-7676766e4f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-16 18:40:07.062542: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-16 18:40:07.309807: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-16 18:40:07.372343: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-16 18:40:07.770851: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-16 18:40:09.867127: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asreen-mohammad/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8426 - loss: 0.5161 - val_accuracy: 1.0000 - val_loss: 0.2848\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2745 - val_accuracy: 1.0000 - val_loss: 0.2459\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2379 - val_accuracy: 1.0000 - val_loss: 0.2155\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2091 - val_accuracy: 1.0000 - val_loss: 0.1907\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1853 - val_accuracy: 1.0000 - val_loss: 0.1697\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1651 - val_accuracy: 1.0000 - val_loss: 0.1518\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1479 - val_accuracy: 1.0000 - val_loss: 0.1362\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1328 - val_accuracy: 1.0000 - val_loss: 0.1226\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1196 - val_accuracy: 1.0000 - val_loss: 0.1106\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.1080 - val_accuracy: 1.0000 - val_loss: 0.1000\n",
      "L2 Regularization Train Accuracy: 100.00%\n",
      "L2 Regularization Validation Accuracy: 100.00%\n",
      "L2 Regularization Test Accuracy: 100.00%\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9948 - loss: 0.0843 - val_accuracy: 1.0000 - val_loss: 4.0117e-09\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.4602e-06 - val_accuracy: 1.0000 - val_loss: 3.1970e-10\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.6006e-07 - val_accuracy: 1.0000 - val_loss: 2.2216e-10\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.9938e-08 - val_accuracy: 1.0000 - val_loss: 2.1143e-10\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.5946e-07 - val_accuracy: 1.0000 - val_loss: 2.0837e-10\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.0731e-06 - val_accuracy: 1.0000 - val_loss: 2.0215e-10\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.9182e-07 - val_accuracy: 1.0000 - val_loss: 1.9726e-10\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.3721e-07 - val_accuracy: 1.0000 - val_loss: 1.9481e-10\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.6539e-08 - val_accuracy: 1.0000 - val_loss: 1.9428e-10\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.8064e-08 - val_accuracy: 1.0000 - val_loss: 1.9394e-10\n",
      "Dropout Train Accuracy: 100.00%\n",
      "Dropout Validation Accuracy: 100.00%\n",
      "Dropout Test Accuracy: 100.00%\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9948 - loss: 0.1408 - val_accuracy: 1.0000 - val_loss: 0.0944\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0962 - val_accuracy: 1.0000 - val_loss: 0.0937\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0909 - val_accuracy: 1.0000 - val_loss: 0.0821\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0793 - val_accuracy: 1.0000 - val_loss: 0.0711\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0687 - val_accuracy: 1.0000 - val_loss: 0.0618\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0598 - val_accuracy: 1.0000 - val_loss: 0.0539\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0521 - val_accuracy: 1.0000 - val_loss: 0.0471\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0455 - val_accuracy: 1.0000 - val_loss: 0.0411\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0398 - val_accuracy: 1.0000 - val_loss: 0.0360\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0348 - val_accuracy: 1.0000 - val_loss: 0.0315\n",
      "Weight Decay Train Accuracy: 100.00%\n",
      "Weight Decay Validation Accuracy: 100.00%\n",
      "Weight Decay Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Assuming OpenCV is installed for image processing\n",
    "train_dir = \"/home/asreen-mohammad/Desktop/project/train\"\n",
    "val_dir = \"/home/asreen-mohammad/Desktop/project/validation\"\n",
    "test_dir = \"/home/asreen-mohammad/Desktop/project/test\"\n",
    "\n",
    "# Initialize parameters\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "input_shape = (28, 28, 3)  # Assuming images are resized to 28x28 and have 3 channels\n",
    "\n",
    "# Regularization parameters\n",
    "l2_regularization = 0.001  # L2 regularization parameter\n",
    "dropout_rate = 0.2  # Dropout rate\n",
    "weight_decay = 0.0001  # Weight decay parameter\n",
    "\n",
    "# Function to load and preprocess data using TensorFlow\n",
    "def load_data_tf(folder_path, input_shape):\n",
    "    X = []\n",
    "    y = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\") or file.endswith(\".png\"):  # Assuming images are in JPG or PNG format\n",
    "                img_path = os.path.join(root, file)\n",
    "                label = 1 if \"positive\" in root else 0  # Example: folder structure decides the label\n",
    "                img = tf.keras.preprocessing.image.load_img(img_path, target_size=(input_shape[0], input_shape[1]))\n",
    "                img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "                X.append(img_array)\n",
    "                y.append(label)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "# Load training data\n",
    "X_train, y_train = load_data_tf(train_dir, input_shape)\n",
    "X_train = X_train / 255.0\n",
    "\n",
    "# Load testing data\n",
    "X_test, y_test = load_data_tf(test_dir, input_shape)\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Load validation data\n",
    "X_val, y_val = load_data_tf(val_dir, input_shape)\n",
    "X_val = X_val / 255.0\n",
    "\n",
    "# Define the neural network architecture for L2 regularization\n",
    "model_l2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_regularization)),\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_regularization)),\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(l2_regularization))\n",
    "])\n",
    "\n",
    "# Compile the model for L2 regularization\n",
    "model_l2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with L2 regularization\n",
    "history_l2 = model_l2.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_val, y_val), verbose=1)\n",
    "\n",
    "# Evaluate accuracy for L2 regularization on train data\n",
    "l2_train_accuracy = model_l2.evaluate(X_train, y_train, verbose=0)[1]\n",
    "print(f\"L2 Regularization Train Accuracy: {l2_train_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Evaluate accuracy for L2 regularization on validation data\n",
    "l2_val_accuracy = model_l2.evaluate(X_val, y_val, verbose=0)[1]\n",
    "print(f\"L2 Regularization Validation Accuracy: {l2_val_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Evaluate accuracy for L2 regularization on test data\n",
    "l2_test_accuracy = model_l2.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(f\"L2 Regularization Test Accuracy: {l2_test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Define the neural network architecture for Dropout regularization\n",
    "model_dropout = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model for Dropout regularization\n",
    "model_dropout.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with Dropout regularization\n",
    "history_dropout = model_dropout.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_val, y_val), verbose=1)\n",
    "\n",
    "# Evaluate accuracy for Dropout regularization on train data\n",
    "dropout_train_accuracy = model_dropout.evaluate(X_train, y_train, verbose=0)[1]\n",
    "print(f\"Dropout Train Accuracy: {dropout_train_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Evaluate accuracy for Dropout regularization on validation data\n",
    "dropout_val_accuracy = model_dropout.evaluate(X_val, y_val, verbose=0)[1]\n",
    "print(f\"Dropout Validation Accuracy: {dropout_val_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Evaluate accuracy for Dropout regularization on test data\n",
    "dropout_test_accuracy = model_dropout.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(f\"Dropout Test Accuracy: {dropout_test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Define the neural network architecture for Weight Decay regularization\n",
    "model_weight_decay = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(weight_decay)),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(weight_decay)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(weight_decay))\n",
    "])\n",
    "\n",
    "# Compile the model for Weight Decay regularization\n",
    "optimizer_weight_decay = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model_weight_decay.compile(optimizer=optimizer_weight_decay, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with Weight Decay regularization\n",
    "history_weight_decay = model_weight_decay.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_val, y_val), verbose=1)\n",
    "\n",
    "# Evaluate accuracy for Weight Decay regularization on train data\n",
    "weight_decay_train_accuracy = model_weight_decay.evaluate(X_train, y_train, verbose=0)[1]\n",
    "print(f\"Weight Decay Train Accuracy: {weight_decay_train_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Evaluate accuracy for Weight Decay regularization on validation data\n",
    "weight_decay_val_accuracy = model_weight_decay.evaluate(X_val, y_val, verbose=0)[1]\n",
    "print(f\"Weight Decay Validation Accuracy: {weight_decay_val_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Evaluate accuracy for Weight Decay regularization on test data\n",
    "weight_decay_test_accuracy = model_weight_decay.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(f\"Weight Decay Test Accuracy: {weight_decay_test_accuracy * 100:.2f}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c5855d4-e7da-4246-abb4-29d859231238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, SGD Training Accuracy: 1.00\n",
      "Epoch 2, SGD Training Accuracy: 1.00\n",
      "Epoch 3, SGD Training Accuracy: 1.00\n",
      "Epoch 4, SGD Training Accuracy: 1.00\n",
      "Epoch 5, SGD Training Accuracy: 1.00\n",
      "SGD Validation Accuracy: 1.00\n",
      "SGD Testing Accuracy: 1.00\n",
      "Epoch 1, MBGD Training Accuracy: 1.00\n",
      "Epoch 2, MBGD Training Accuracy: 1.00\n",
      "Epoch 3, MBGD Training Accuracy: 1.00\n",
      "Epoch 4, MBGD Training Accuracy: 1.00\n",
      "Epoch 5, MBGD Training Accuracy: 1.00\n",
      "MBGD Validation Accuracy: 1.00\n",
      "MBGD Testing Accuracy: 1.00\n",
      "Epoch 1, GD Training Accuracy: 1.00\n",
      "Epoch 2, GD Training Accuracy: 1.00\n",
      "Epoch 3, GD Training Accuracy: 1.00\n",
      "Epoch 4, GD Training Accuracy: 1.00\n",
      "Epoch 5, GD Training Accuracy: 1.00\n",
      "GD Validation Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Define paths to your data folders\n",
    "training_dir = '/home/asreen-mohammad/Desktop/project/train/'\n",
    "validation_dir = '/home/asreen-mohammad/Desktop/project/validation/'\n",
    "testing_dir = '/home/asreen-mohammad/Desktop/project/test/'\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 5\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Load and preprocess training, validation, and testing data\n",
    "training_data = []\n",
    "training_labels = []\n",
    "for filename in os.listdir(training_dir):\n",
    "    if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
    "        img_path = os.path.join(training_dir, filename)\n",
    "        img = Image.open(img_path)\n",
    "        img = img.convert('L')  # Convert to grayscale\n",
    "        img = img.resize((28, 28))  # Resize to 28x28 pixels\n",
    "        img_array = np.array(img)\n",
    "        training_data.append(img_array.flatten())\n",
    "        training_labels.append(1)  # Example label, adjust based on your dataset\n",
    "\n",
    "validation_data = []\n",
    "validation_labels = []\n",
    "for filename in os.listdir(validation_dir):\n",
    "    if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
    "        img_path = os.path.join(validation_dir, filename)\n",
    "        img = Image.open(img_path)\n",
    "        img = img.convert('L')  # Convert to grayscale\n",
    "        img = img.resize((28, 28))  # Resize to 28x28 pixels\n",
    "        img_array = np.array(img)\n",
    "        validation_data.append(img_array.flatten())\n",
    "        validation_labels.append(1)  # Example label, adjust based on your dataset\n",
    "\n",
    "testing_data = []\n",
    "testing_labels = []\n",
    "for filename in os.listdir(testing_dir):\n",
    "    if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
    "        img_path = os.path.join(testing_dir, filename)\n",
    "        img = Image.open(img_path)\n",
    "        img = img.convert('L')  # Convert to grayscale\n",
    "        img = img.resize((28, 28))  # Resize to 28x28 pixels\n",
    "        img_array = np.array(img)\n",
    "        testing_data.append(img_array.flatten())\n",
    "        testing_labels.append(1)  # Example label, adjust based on your dataset\n",
    "\n",
    "# SGD Training\n",
    "weights_sgd = np.random.randn(len(training_data[0]))\n",
    "bias_sgd = 0.1\n",
    "training_accuracy_sgd = []\n",
    "for epoch in range(epochs):\n",
    "    correct = 0\n",
    "    for i in range(len(training_data)):\n",
    "        prediction = np.dot(weights_sgd, training_data[i]) + bias_sgd\n",
    "        prediction = 1 if prediction >= 0 else 0\n",
    "        error = training_labels[i] - prediction\n",
    "        weights_sgd += learning_rate * error * training_data[i]\n",
    "        bias_sgd += learning_rate * error\n",
    "        correct += 1 if prediction == training_labels[i] else 0\n",
    "    training_accuracy_sgd.append(correct / len(training_data))\n",
    "    print(f\"Epoch {epoch+1}, SGD Training Accuracy: {training_accuracy_sgd[-1]:.2f}\")\n",
    "\n",
    "# Evaluate on validation data with SGD\n",
    "predicted_labels = (np.dot(np.expand_dims(weights_sgd, axis=0), np.transpose(validation_data)) + bias_sgd) >= 0\n",
    "predicted_labels = predicted_labels.astype(int)\n",
    "validation_accuracy_sgd = np.mean(predicted_labels == validation_labels)\n",
    "\n",
    "print(f\"SGD Validation Accuracy: {validation_accuracy_sgd:.2f}\")\n",
    "\n",
    "# Evaluate on testing data with SGD\n",
    "predicted_labels = (np.dot(np.expand_dims(weights_sgd, axis=0), np.transpose(testing_data)) + bias_sgd) >= 0\n",
    "testing_accuracy_sgd = np.mean(np.all(predicted_labels == testing_labels, axis=1))\n",
    "\n",
    "\n",
    "print(f\"SGD Testing Accuracy: {testing_accuracy_sgd:.2f}\")\n",
    "\n",
    "# Mini-Batch Gradient Descent (MBGD) Training\n",
    "weights_mbgd = np.random.randn(len(training_data[0]))\n",
    "bias_mbgd = 0.1\n",
    "training_accuracy_mbgd = []\n",
    "for epoch in range(epochs):\n",
    "    correct = 0\n",
    "    for i in range(0, len(training_data), 32):  # Batch size of 32\n",
    "        batch_data = training_data[i:i+32]\n",
    "        batch_labels = training_labels[i:i+32]\n",
    "        for j in range(len(batch_data)):\n",
    "            prediction = np.dot(weights_mbgd, batch_data[j]) + bias_mbgd\n",
    "            prediction = 1 if prediction >= 0 else 0\n",
    "            error = batch_labels[j] - prediction\n",
    "            weights_mbgd += learning_rate * error * batch_data[j]\n",
    "            bias_mbgd += learning_rate * error\n",
    "            correct += 1 if prediction == batch_labels[j] else 0\n",
    "    training_accuracy_mbgd.append(correct / len(training_data))\n",
    "    print(f\"Epoch {epoch+1}, MBGD Training Accuracy: {training_accuracy_mbgd[-1]:.2f}\")\n",
    "\n",
    "# Evaluate on validation data with MBGD\n",
    "predicted_labels = (np.dot(np.expand_dims(weights_mbgd, axis=0), np.transpose(validation_data)) + bias_mbgd) >= 0\n",
    "validation_accuracy_mbgd = np.mean(np.all(predicted_labels == validation_labels, axis=1))\n",
    "print(f\"MBGD Validation Accuracy: {validation_accuracy_mbgd:.2f}\")\n",
    "\n",
    "# Evaluate on testing data with MBGD\n",
    "\n",
    "predicted_labels = (np.dot(np.expand_dims(weights_mbgd, axis=0), np.transpose(testing_data)) + bias_mbgd) >= 0\n",
    "testing_accuracy_mbgd = np.mean(np.all(predicted_labels == testing_labels, axis=1))\n",
    "\n",
    "\n",
    "\n",
    "print(f\"MBGD Testing Accuracy: {testing_accuracy_mbgd:.2f}\")\n",
    "\n",
    "# Gradient Descent (GD) Training\n",
    "weights_gd = np.random.randn(len(training_data[0]))\n",
    "bias_gd = 0.1\n",
    "training_accuracy_gd = []\n",
    "for epoch in range(epochs):\n",
    "    correct = 0\n",
    "    for i in range(len(training_data)):\n",
    "        prediction = np.dot(weights_gd, training_data[i]) + bias_gd\n",
    "        prediction = 1 if prediction >= 0 else 0\n",
    "        error = training_labels[i] - prediction\n",
    "        weights_gd += learning_rate * error * training_data[i]\n",
    "        bias_gd += learning_rate * error\n",
    "        correct += 1 if prediction == training_labels[i] else 0\n",
    "    training_accuracy_gd.append(correct / len(training_data))\n",
    "    print(f\"Epoch {epoch+1}, GD Training Accuracy: {training_accuracy_gd[-1]:.2f}\")\n",
    "\n",
    "#Evaluate on validation data with GD\n",
    "predicted_labels = (np.dot(np.expand_dims(weights_gd, axis=0), np.transpose(validation_data)) + bias_gd) >= 0\n",
    "validation_accuracy_GD = np.mean(np.all(predicted_labels == validation_labels, axis=1))\n",
    "print(f\"GD Validation Accuracy: {validation_accuracy_mbgd:.2f}\")\n",
    "\n",
    "# Evaluate on testing data with GD\n",
    "\n",
    "predicted_labels = (np.dot(np.expand_dims(weights_gd, axis=0), np.transpose(testing_data)) + bias_gd) >= 0\n",
    "testing_accuracy_GD = np.mean(np.all(predicted_labels == testing_labels, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd556e9-ffcf-4efe-bb8f-3a7c0b842f51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
